<!DOCTYPE html>


  <html class="light page-post">


<head>
  <meta charset="utf-8">
  
  <title>机器学习简单笔记 | feilengcui008</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="机器学习," />
  

  <meta name="description" content="Machine Learning Simple Notes(一些基础的notes…)
BasicsMachine Learning
Model(模型) + Evaluation(评估标准) + Optimization(优化算法) + Validation(验证)
Using datasets D to learn specific model G from model space(hypothe">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习简单笔记">
<meta property="og:url" content="/2015/09/12/机器学习简单笔记/index.html">
<meta property="og:site_name" content="feilengcui008">
<meta property="og:description" content="Machine Learning Simple Notes(一些基础的notes…)
BasicsMachine Learning
Model(模型) + Evaluation(评估标准) + Optimization(优化算法) + Validation(验证)
Using datasets D to learn specific model G from model space(hypothe">
<meta property="og:updated_time" content="2017-04-01T09:24:35.427Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习简单笔记">
<meta name="twitter:description" content="Machine Learning Simple Notes(一些基础的notes…)
BasicsMachine Learning
Model(模型) + Evaluation(评估标准) + Optimization(优化算法) + Validation(验证)
Using datasets D to learn specific model G from model space(hypothe">

  

  
    <link rel="icon" href="/favicon.ico">
  

  <link href="/css/styles.css?v=c114cbe6" rel="stylesheet">


  
    <link rel="stylesheet" href="/css/personal-style.css" type="text/css">
  

  

  

  


  
    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  

  
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  
</head>

<body>

  <div class="sidebar-toggle">
  <a href="/"><span class="hfont">H</span></a>
</div>


  

  <!--
<div class="post-header">
   

</div>
-->


  <div id="toc" class="toc-article">
    <strong class="toc-title">Posts List</strong>
    <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Machine_Learning_Simple_Notes"><span class="toc-text">Machine Learning Simple Notes</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Basics"><span class="toc-text">Basics</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Machine_Learning"><span class="toc-text">Machine Learning</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ML_Problem_Classification"><span class="toc-text">ML Problem Classification</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Theories"><span class="toc-text">Theories</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Algorithms_28Models_29"><span class="toc-text">Algorithms(Models)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Supervised_Learning"><span class="toc-text">Supervised Learning</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Unsupervised_Learning"><span class="toc-text">Unsupervised Learning</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Others"><span class="toc-text">Others</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Techniques"><span class="toc-text">Techniques</span></a></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-机器学习简单笔记" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">机器学习简单笔记</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2015.09.12</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>feilengcui008</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </span>



      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      

      
        <i class="icon-comment"></i> 
        <span class="ds-thread-count" data-thread-key="post-机器学习简单笔记"><i class="fa fa-spinner fa-spin"></i></span> 条评论
      
      
    </div>
  </header>

  <div class="article-content">
    
      <h3 id="Machine_Learning_Simple_Notes"><a href="#Machine_Learning_Simple_Notes" class="headerlink" title="Machine Learning Simple Notes"></a>Machine Learning Simple Notes</h3><p>(一些基础的notes…)</p>
<h4 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h4><h5 id="Machine_Learning"><a href="#Machine_Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h5><ul>
<li>Model(模型) + Evaluation(评估标准) + Optimization(优化算法) + Validation(验证)</li>
<li>Using datasets D to learn specific model G from model space(hypothesis space) H<br>so that G is close to the best model F in H.</li>
</ul>
<h5 id="ML_Problem_Classification"><a href="#ML_Problem_Classification" class="headerlink" title="ML Problem Classification"></a>ML Problem Classification</h5><ul>
<li>out space<ul>
<li>Classification<ul>
<li>binary-class </li>
<li>multi-class<ul>
<li>one-v-all:k binary Classifiers</li>
<li>one-v-one:train a binary classifier for each pair of class,<pre><code>k(k-1)/2 SVM binary classifiers 
</code></pre></li>
<li>softmax regression(multiclass logistic regression)</li>
</ul>
</li>
<li>structure(sentence classification)</li>
</ul>
</li>
<li>Regression</li>
<li>Clustering</li>
</ul>
</li>
<li>data input space <ul>
<li>Supervised Learning</li>
<li>Unsupervised Learning</li>
<li>Semi-supervised Learning</li>
<li>Reinforce Learning</li>
</ul>
</li>
<li>algorithms space <ul>
<li>Parameter</li>
<li>Non-parameter<ul>
<li>K-nearest Neighbors</li>
<li>Kernel Estimation</li>
<li>Locally Weighted Linear Regression</li>
</ul>
</li>
<li>Semi-parameter</li>
</ul>
</li>
<li>learning with different protocols<ul>
<li>batch learning </li>
<li>online learning</li>
<li>active learning</li>
</ul>
</li>
<li>features input space<ul>
<li>concrete features</li>
<li>raw features </li>
<li>abstract features</li>
</ul>
</li>
</ul>
<h4 id="Theories"><a href="#Theories" class="headerlink" title="Theories"></a>Theories</h4><ul>
<li><p>Describe the learning feasibility and learning process(PAC learning theory)</p>
<ul>
<li>finite hypothesis space H</li>
<li>infinite hypothesis space H <ul>
<li>dichotomy<br>(a specific combination case of N input samples),denotes<br>H(S1, S2, S3,…, Sn)(函数簇，每个函数簇中的假设函数属于同一dichotomy)</li>
<li>growth function<br>(maximum dichotomy[最大函数簇] for a specific hypothesis space H and N samples), denots mH(N)</li>
<li>bound function<br>(maximum growth function for a specific break point k and N samples with different H)<br>denotes B(N,k), B(N,k) &lt;= B(N-1,k) + B(N-1,k-1) &lt; N^(k-1) = N^(Dvc) </li>
<li>本质上由于样本集合是稀疏离散的，导致无限维假设空间中只有某些簇对样本能起到有效分割，每一簇中的假设函数对此样本集合起到相同的分割作用，也就是在hoeffding不等式中，每一簇中的假设函数导致|E(in,h)-E(out,h)|&gt;epsilon误差的概率是重合的(不独立)，其概率P(|E(in,h)-E(out,h)|&gt;epsilon)是同时发生的，反映所有假设函数P(E(in,h)-E(out,h)&gt;epsilon)的并集不会无限增大，及不等式右侧2<em>M</em>e{-2<em>epsilon^2</em>N}中的M退化为有限维，而此维数受到样本集合大小N限制。从而转变为有限维的情况，而在有限维情况下有结论：给定足够大的N，能够使得Probably Approximately Correct(PAC)下，有<br>P(for any h belong to H,|E(in,h)-E(out,h)|&gt;epsilon) &lt; 2<em>M</em>e{-2<em>epsilon^2</em>N}，由此从理论上证明了学习背后的可行性和正确性。意即确实学习了，improve了。</li>
</ul>
</li>
<li>Empirical Risk Minimization </li>
<li>VC bound<ul>
<li>for any h in H<br>P(|E(in,h)-E(out,h)|&gt;epsilon) &lt;= 4<em>mH(2N)</em>exp(-1/8<em>epsilon^2</em>N) &lt;= 4<em>(2N)^(k-1)</em>exp()</li>
</ul>
</li>
<li>VC dimension:Maximum_not_break_point(minimum_break_point-1)<ul>
<li>Dvc不是无限大(存在break_point),给定足够大的N,能保证PAC条件下hoeffding不等式<br>成立。即在一定误差下能用E(in)估计E(out),即能用输入datasets估计generalization的情况。</li>
<li>假设函数空间H最多能把Dvc数量的样本集合shatter，即能学习样本集合的所有组合,可以<br>衡量假设函数空间的学习复杂度</li>
<li>VC dimension与输入样本特征数量的关系:Dvc = d(特征数量)+1<ul>
<li>证明思路：Dvc &lt;= d+1 &amp;&amp; Dvc &gt;= d+1</li>
<li>Dvc &lt;= d+1 &lt;=&gt;<br>对于d+2个输入的任意组合,不能shatter &lt;=&gt;<br>不存在W,使得WX=Y成立 &lt;=&gt;<br>由于X是(N+2)*(N+1)维的,而且输入向量之间线性无关,所以方程个数大于(W)自由变量的个数,导致W无解</li>
<li>Dvc &gt;= d+1 &lt;=&gt;<br>能shatter d+1个输入的某个组合 &lt;=&gt;<br>存在W,使得WX=Y成立 &lt;=&gt;<br>由于X是(N+1)*(N+1)维的,且可构造X为正定矩阵,所以X可逆,即W=inv(X)Y,有解</li>
</ul>
</li>
<li>衡量假设函数空间的学习复杂度(自由度)，或者说从另一方面衡量样本集合的学习能力 </li>
<li>VC dimension与样本数量N、特征维数的关系</li>
<li>with propability 1-a<br>E(out,g) &lt;= E(in,g) + sqrt(8/N<em>ln[4</em>((2N)^Dvc)/a]) = E(in,g) + omega(N,H,a)(模型复杂度model complexity)</li>
<li>sample compexity N</li>
</ul>
</li>
</ul>
</li>
<li><p>Bias and Variance(Underfitting and Overfitting) trade-off</p>
<ul>
<li>underfitting </li>
<li>overfitting <ul>
<li>datasets too small </li>
<li>noise too large(stochastic noise and deterministic noise[depends on H])</li>
<li>model too compexity(VC dimension too big)</li>
</ul>
</li>
</ul>
</li>
<li>Regularization <ul>
<li>本质：通过增加对特征系数w的限制，减少需要搜索的假设空间的复杂度或者说维数，从而使得模型复杂度较高的同时较少deterministic noise，从而得到较好的tradeoff，<br>另一方面，从贝叶斯角度，相当于添加了先验知识(先验概率)，然后极大化后验概率。</li>
</ul>
</li>
<li>Training Error(Risk)</li>
<li>Model Selection</li>
<li>Feature Selection </li>
<li>Cross Validation </li>
<li>Model Metrics<ul>
<li>accuracy,precision,recall <ul>
<li>accuracy = TP+TN/TP+TF+NP+NF  ==&gt; 正确分类的比例</li>
<li>precision = TP/TP+FP ==&gt; 衡量不会将负样本错误分类为正样本的概率(欺诈检测)</li>
<li>recall = TP/TP+FN ==&gt; 衡量从样本集区分全体正样本的能力  </li>
</ul>
</li>
<li>confusion_matrix <ul>
<li>行代表prediction类别，列代表事实上的类别，A(i,j)表示将类别i分类为类别j的数量 </li>
</ul>
</li>
<li>f1-measure = 2<em>(precision</em>recall)/(precision+recall)[in f-measure where a=1]<ul>
<li>f-measure = (a^2+1)<em>(precision</em>recall)/(precision+recall)</li>
<li>综合考虑精确率与召回率的影响 </li>
</ul>
</li>
<li>ROC and AUC ==&gt; inbalanced datasets </li>
</ul>
</li>
</ul>
<h4 id="Algorithms_28Models_29"><a href="#Algorithms_28Models_29" class="headerlink" title="Algorithms(Models)"></a>Algorithms(Models)</h4><h5 id="Supervised_Learning"><a href="#Supervised_Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h5><ul>
<li>1.Least Square Mean(LSM)</li>
<li>2.Logistic Regression(LR)</li>
<li>3.Percepton</li>
<li>4.Naive Bayes(NB)</li>
<li>5.Support Vector Machine(SVM)</li>
<li>6.Decision Tree</li>
<li>7.Neighbors</li>
<li>8.Linear Discriminative Analysis(LDA)</li>
<li>9.Resemble Methods<ul>
<li>(1)Boosting : Gradient Boosted Decision[Regression] Trees(GBRT[GBDT])</li>
<li>(2)Bagging  : Random Forests</li>
</ul>
</li>
</ul>
<h5 id="Unsupervised_Learning"><a href="#Unsupervised_Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h5><p>Clustering / Dimension Reduction / Density Estimation</p>
<ul>
<li>1.KMeans Clustering</li>
<li>2.Hierarchy Clustering</li>
<li>3.Expectation Maxmization(EM)</li>
<li>4.Gaussian Mixture Models(GMM)</li>
<li>5.Density-Based Spatial Clustering of Applications with Noise(DBSCAN)</li>
<li>6.Mean Shift</li>
</ul>
<h5 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h5><ul>
<li>1.Artificial Neural Network and Deep Learning</li>
<li>2.Dimension Reduction<ul>
<li>(1)PCA/Kernel PCA</li>
<li>(2)Matrix Factorization/SVD</li>
</ul>
</li>
<li>3.Gaussian Process</li>
<li>4.Bayesian Network and Graphical Models</li>
<li>5.LDA</li>
<li>6.PageRank</li>
<li>7.Apriori</li>
<li>8.Empirical Risk Minimization(ERM)</li>
</ul>
<h4 id="Techniques"><a href="#Techniques" class="headerlink" title="Techniques"></a>Techniques</h4><p>This section includes some theories aspects and techniques used in machine learning.</p>
<ul>
<li>Normalization</li>
<li>Principle Componets Ananysis</li>
<li>Singular Value Decomposition</li>
<li><p>Matrix Factorization</p>
</li>
<li><p>inbalanced datasets </p>
<ul>
<li>oversampling and undersampling </li>
<li>different metrics such as AUC </li>
<li>ensemble different algorithms </li>
<li>cost matrix </li>
</ul>
</li>
<li><p>nonlinear transformation for linear models </p>
</li>
<li><p>拉格朗日数乘法的本质</p>
<ul>
<li>min{ f(x) } ,  s.t. g(x) &lt;= 0</li>
<li>L(x) = f(x) + C*g(x) with C&gt;0</li>
<li>L(x)’ = f’ + C*g’ = 0 ==&gt; 假设f的等值线与g在x0处相交且最小，f’和g’在x0处的法向量共线，<br>也即f的梯度没有沿着g曲线的切向分量了，梯度下降停止</li>
</ul>
</li>
</ul>
<blockquote>
<p>ref:机器学习基石课程</p>
</blockquote>

    
  </div>
</article>


   

   



</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">Close</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="ROUND_RECT"
              href="/"
              rel="noopener noreferrer"
              target="_self"
              >
              Home
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="ROUND_RECT"
              href="/archives/"
              rel="noopener noreferrer"
              target="_self"
              >
              Archives
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="ROUND_RECT"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              About
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    

    
  <section class="duoshuo-comments">
    <!-- 多说评论框 start -->
    <div class="ds-thread" data-thread-key="post-机器学习简单笔记" 
      data-title="机器学习简单笔记" data-url="/2015/09/12/机器学习简单笔记/index.html"></div>
    <!-- 多说评论框 end -->
  </section>




  <script type="text/javascript">
  var duoshuoQuery = {short_name:"feilengcui008"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>


    

  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
